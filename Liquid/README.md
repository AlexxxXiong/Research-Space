# Liquid: Intelligent Resource Estimation and Network-Efficient Scheduling for Deep Learning
Jobs on Distributed GPU Clusters
背景：1) 现有 GPU 资源管理需要用户指定，不准确导致低利用率；2) 未考虑集群的网络特性，导致低 job 性能。

Liquid 是一个**高效的 GPU 资源管理平台**，**面向容器**实现，基于**参数服务器 (PS) 架构**，支持**智能资源需求评估**和**考虑网络带宽的集群资源调度**。Liquid 使用一个**回归模型 (随机森林算法)** 来评估 job 的资源需求；提出集群网络高效的调度策略，包括**即时模式** (jobs 逐个到来，使用**基于贪心和自建 metric (考虑 PS 通信 cost + node 内 GPU 利用率) 的 best-fit 算法**) 和**批模式** (jobs 批量到来，群组调度形成**多维装箱问题** (NP-C)，使用**组遗传算法**来求解并迭代优化)；提出包括**预调度数据传输** (前一个任务刚结束训练进入保存阶段，后一个立即开始训练，减少 GPU idle，需要模型预测各阶段时间)，**细粒度 GPU 共享** (需要模型预测 GPU 利用率和占用显存) 和**事件驱动通信** (不由 global 调度器周期性检查，而是 local 资源管理器实时监控，并在资源状态改变时立即汇报，**靠谱**) 在内的三个系统级优化。

-------



### 1. 使用 model 预测 job 所需资源的依据：

- 资源需求向量：1) **GPU 数目**；2) **GPU 显存**；3) **网络带宽资源**；
- 观察：
    - 使用小数据集验证模型有效性；
    - AutoML 自动重复搜索最佳超参；
    - 利用新数据更新生产环境下的模型；
- 许多 jobs 仅超参和数据集大小改变，且相同模型的性能有规律性 -> 可以利用历史资源数据和参数相对大小来评估 job 资源需求；
- **随机森林算法**，**输入特征为超参**，**输出标签为资源需求向量 + GPU 算力利用率标准差**。

------



### 2. 考虑网络带宽的调度算法设计

- 在 Liquid，用户不需要修改已有代码或框架，其**资源调度问题为：找到从容器到空闲计算节点的映射，并满足特定资源需求**；

- 调度关注**减少平均 JCT 和 makespan** (完成时间，即 max JCT)。总时间考虑了**发射时间、训练时间、参数同步时间 (主要) 和模型保存时间**；

- **节点间通信开销的建模**：根据 node_1 和 node_2 是否位于相同 rack (机架，与 switch 绑定) / 相同 domain (域)，利用 rack / domain 内的 **nodes 数目直接表示 cost** (不考虑跨域，通信质量差)；

- 调度策略应减少节点间和 switches 间的通信量；
- **Best-fit 算法**的数学建模部分：
    - **job_i 的通信开销**定义为调度策略 k 下，所有 ps 和 worker 间通信 cost 的总和；
    - **Fitness** = - (当前请求的 GPUs + 已使用的 GPUs) / 总 GPUs < 0，这样 min score 等价于 max fitness；
    - **Score** (**优化目标为贪心地 min score for job_i**) 定义为由通信开销和每节点 load 和的加权和组成；
    - **这样建模的好处是 metric 可以直接实时算出来 (cost <- node 数目，fitness <- node 内资源使用情况)，不用 profile**。
- **群组调度**的数学建模部分：
    - 最开始的优化目标是最小化组内所有 jobs 的 score 之和 -> **多维装箱问题**，NP-complete；
    - 使用**组遗传算法**进行求解，将 ps/worker instances 在多节点上分组放置，并以 round-based 的方式在给定时限内迭代优化；
    - 用 first-fit 和 rand-fit 作为初始调度方案；
    - **遗传算法的优化目标**是：maximize GeneticFitness = - sum(score_i) - 调度策略需要的 nodes 数目；
        - 考虑 nodes 数目以保证 locality 并加快算法收敛；
        - 选择 fitness 高的，并保留一些普通的，以防收敛到局部最优；删除 invalid 的调度方案。

-------



### 3. 三类系统级优化

- **预调度数据传输** (前一个任务刚结束训练进入保存阶段，后一个立即开始训练，减少 GPU idle，需要模型预测各阶段时间)；
    - 该优化的实现依赖于利用一个模型预测 job 各阶段时间 (和 Optimus 类似，不靠谱)；
- **细粒度 GPU 共享** (将低资源利用率的多个 jobs 放在相同 GPU 上混布)；
    - 需要模型预测 GPU 利用率和占用显存的变化曲线，并将平均 GPU 利用率和最大占用 GPU 显存作为预测值；
- **事件驱动通信** (不由 global 调度器周期性检查，而是 local 资源管理器实时监控，并在资源状态改变时立即汇报，靠谱) 在内的三个系统级优化；
    - 调度器周期性检查资源状态 (heartbeat) 会导致空闲。
